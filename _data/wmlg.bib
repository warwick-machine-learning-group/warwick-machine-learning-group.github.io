
@inproceedings{NMSR2024,
  title={Corruption-robust Offline Two-player Zero-sum Markov Games},
  author={Nika, Andi and Mandal, Debmalya and Singla, Adish and Radanovic, Goran},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2024},
  organization={PMLR}
}

@article{chen2023polynomial,
  title={Polynomial-Time Pseudodeterministic Construction of Primes},
  author={Chen, Lijie and Lu, Zhenjian and Oliveira, Igor C and Ren, Hanlin and Santhanam, Rahul},
  journal={arXiv preprint arXiv:2305.15140},
  year={2023}
}


@article{gill2023bayesian,
  title={Bayesian Inference of Reproduction Number from Epidemiological and Genetic Data Using Particle MCMC},
  author={Gill, Alicia and Koskela, Jere and Didelot, Xavier and Everitt, Richard G},
  journal={arXiv preprint arXiv:2311.09838},
  year={2023}
}

@inproceedings{riou2023adaptive,
  title={Adaptive Tuning for Metropolis Adjusted Langevin Trajectories},
  author={Riou-Durand, Lionel and Sountsov, Pavel and Vogrinc, Jure and Margossian, Charles and Power, Sam},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={8102--8116},
  year={2023},
  organization={PMLR}
}

@inproceedings{zhu2023benign,
  title={Benign overfitting in deep neural networks under lazy training},
  author={Zhu, Zhenyu and Liu, Fanghui and Chrysos, Grigorios and Locatello, Francesco and Cevher, Volkan},
  booktitle={International Conference on Machine Learning},
  pages={43105--43128},
  year={2023},
  organization={PMLR}
}

@inproceedings{wu2023convergence,
  title={On the convergence of shallow Transformers.},
  author={Wu, Yongtao and Liu, Fanghui and Chrysos, Grigorios and Cevher, Volkan},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023}
}

@inproceedings{ye2023intialization,
  title={Initialization matters: Privacy-utility analysis of overparameterized neural networks},
  author={Ye, Jiayuan and Zhu, Zhenyu and Liu, Fanghui and Shokri, Reza and Cevher, Volkan},
  booktitle={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{dellaporta2022robust,
  title={Robust Bayesian Inference for Simulator-based Models via the MMD Posterior Bootstrap},
  author={Dellaporta, Charita and Knoblauch, Jeremias and Damoulas, Theodoros and Briol, Fran{\c{c}}ois-Xavier},
  journal={{AISTATS}'22},
  year={2022}
}

@article{maronas2021transforming,
  title={Transforming Gaussian Processes With Normalizing Flows},
  author={Maro{\~n}as, Juan and Hamelijnck, Oliver and Knoblauch, Jeremias and Damoulas, Theodoros},
  journal={The 24th international conference on artificial intelligence and statistics ({AISTATS}'21},
  year={2021}
}

@article{lemercier2021distribution,
  title={Distribution Regression for Sequential Data},
  author={Lemercier, Maud and Salvi, Cristopher and Damoulas, Theodoros and Bonilla, Edwin V and Lyons, Terry},
  journal={The 24th international conference on artificial intelligence and statistics ({AISTATS}'21},
  year={2021}
}

@article{akyildiz2021probabilistic,
  title={Probabilistic sequential matrix factorization},
  author={Akyildiz, {\"O}mer Deniz and van den Burg, Gerrit JJ and Damoulas, Theodoros and Steel, Mark FJ},
  journal={The 24th international conference on artificial intelligence and statistics ({AISTATS}'21)},
  year={2021}
}

@article{manino2019efficiency,
  title={On the efficiency of data collection for multiple Na{\"\i}ve Bayes classifiers},
  author={Manino, Edoardo and Tran-Thanh, Long and Jennings, Nicholas R},
  journal={Artificial Intelligence},
  volume={275},
  pages={356--378},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{manino2019streaming,
  title={Streaming Bayesian Inference for Crowdsourced Classification},
  author={Manino, Edoardo and Tran-Thanh, Long and Jennings, Nicholas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12782--12792},
  year={2019}
}

@inproceedings{vu2020path,
  title={Path Planning Problems with Side Observations-When Colonels Play Hide-and-Seek.},
  author={Vu, Dong Quan and Loiseau, Patrick and Silva, Alonso and Tran-Thanh, Long},
  booktitle={AAAI},
  pages={2252--2259},
  year={2020}
}

@inproceedings{aglietti2020multi,
  title={Multi-task Causal Learning with Gaussian Processes},
  author={Aglietti, Virginia and Damoulas, Theodoros and {\'A}lvarez, Mauricio and Gonz{\'a}lez, Javier},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@inproceedings{bishop2020optimal,
  title={Optimal learning from verified training data},
  author={Bishop, Nicholas and Tran-Thanh, Long and Gerding, Enrico},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@inproceedings{bishop2020adversarial,
  title={Adversarial blocking bandits},
  author={Bishop, Nicholas and Chan, Hau and Mandal, Debmalya and Tran-Thanh, Long},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@article{koskela2020asymptotic,
  title={Asymptotic genealogies of interacting particle systems with an application to sequential Monte Carlo},
  author={Koskela, Jere and Jenkins, Paul A and Johansen, Adam M and Spano, Dario},
  journal={The Annals of Statistics},
  volume={48},
  number={1},
  pages={560--583},
  year={2020},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{richter2020vargrad,
  title={VarGrad: A Low Variance Gradient Estimator for Variational Inference},
  author={Richter, Lorenz and Boustati, Ayman and Nusken, Nikolas and Ruiz, Francisco and Akyildiz, {\"O}mer Deniz },
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@article{tait2020variational,
  title={Variational Autoencoding of PDE Inverse Problems},
  author={Tait, Daniel J and Damoulas, Theodoros},
  journal={arXiv preprint arXiv:2006.15641},
  year={2020}
}

@inproceedings{boustati2020generalized,
  title={Generalized Bayesian Filtering via Sequential Monte Carlo},
  author={Boustati, Ayman and Akyildiz, {\"O}mer Deniz and Damoulas, Theodoros and Johansen, Adam},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@INPROCEEDINGS{boustati2020amortized,
AUTHOR = "Boustati, A., Vakili, S., Hensman, J. and John, S.T",
TITLE = "Amortized variance reduction for doubly stochastic objectives",
BOOKTITLE = "Proceedings of the Thirty-Sixth Conference Annual Conference on Uncertainty in Artificial Intelligence (UAI-20)",
PUBLISHER = "AUAI Press",
YEAR = "2020"
}

@inproceedings{wangnonstationary2020,
  title={Nonstationary Nonseparable Random Fields},
  author={Wang, Kangrui and Hamelijnck, Oliver and Damoulas, Theodoros and Steel, Mark},
  booktitle={International Conference on Machine Learning ({ICML}'20)},
  year={2020},
  url={https://proceedings.icml.cc/static/paper_files/icml/2020/3803-Paper.pdf}
}

@inproceedings{knoblauch2020optimal,
  title={Optimal Continual Learning has Perfect Memory and is NP-hard},
  author={Knoblauch, Jeremias and Husain, Hisham and Diethe, Tom},
  booktitle={International Conference on Machine Learning ({ICML}'20)},
  year={2020},
  url={https://proceedings.icml.cc/static/paper_files/icml/2020/204-Paper.pdf}
}

@article{pollock2020quasi,
  title={Quasi-stationary Monte Carlo and the ScaLE Algorithm},
  author={Pollock, Murray and Fearnhead, Paul and Johansen, Adam M and Roberts, Gareth O},
  journal={Journal of the Royal Statistical Society. Series B: Statistical Methodology},
  year={2020}
}

@inproceedings{chistikov2020convergence,
  title={Convergence of Opinion Diffusion is PSPACE-Complete.},
  author={Chistikov, Dmitry and Lisowski, Grzegorz and Paterson, Mike and Turrini, Paolo},
  booktitle={AAAI},
  pages={7103--7110},
  year={2020}
}

@article{rendell2020global,
  title={Global consensus Monte Carlo},
  author={Rendell, Lewis J and Johansen, Adam M and Lee, Anthony and Whiteley, Nick},
  journal={Journal of Computational and Graphical Statistics},
  number={just-accepted},
  pages={1--29},
  year={2020},
  publisher={Taylor \& Francis}
}

@article{grandi2020personalised,
  title={Personalised rating},
  author={Grandi, Umberto and Stewart, James and Turrini, Paolo},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={34},
  number={2},
  pages={1--38},
  year={2020},
  publisher={Springer}
}

@inproceedings{roman2019multi,
  title={Multi-Population Congestion Games With Incomplete Information.},
  author={Roman, Charlotte and Turrini, Paolo},
  booktitle={IJCAI},
  pages={565--571},
  year={2019}
}

@inproceedings{CormodeDickens19,
  title = {Iterative Hessian Sketch in Input Sparsity Time},
  author = {Cormode, Graham and Dickens, Charlie},
  booktitle = {Proceedings of Beyond First Order Methods in ML (NeurIPS 
workshop)},
  year = {2019},
  abstract = {
  Scalable algorithms to solve optimization and regression tasks even
  approximately, are needed
  to work with large datasets.
  In this paper we study efficient techniques from matrix sketching to
  solve a variety of convex constrained regression problems.
  We adopt ``Iterative Hessian Sketching'' (IHS) and show that the fast
  CountSketch and sparse Johnson-Lindenstrauss Transforms yield
  state-of-the-art accuracy guarantees under IHS, while dramatically
  improving the time cost.
  As a result, we obtain significantly faster algorithms for constrained
  regression, for both sparse and dense inputs.
  Our empirical results show that we can summarize data roughly 100x
  faster for sparse data, and, surprisingly, 10x faster on
  dense data!
Consequently, solutions accurate to within machine precision of the 
optimal solution can be found much faster than the previous state of the 
art.}
}

@inproceedings{2019arXiv190608344H,
       author = {{Hamelijnck}, Oliver and {Damoulas}, Theodoros and {Wang}, Kangrui and
         {Girolami}, Mark},
        title = "{Multi-resolution Multi-task Gaussian Processes}",
    booktitle = {Advances in Neural Information Processing Systems 32 ({NeurIPS'19})},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2019",
        month = "Jun",
archivePrefix = {arXiv},
       eprint = {1906.08344},
 primaryClass = {stat.ML},
          url = {https://ui.adsabs.harvard.edu/abs/2019arXiv190608344H}
}

@inproceedings{2019arXiv190607754O,
       author = {{O'Hara}, Patrick and {Ramanujan}, M.~S. and {Damoulas}, Theodoros},
        title = "{On the Constrained Least-cost Tour Problem}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Artificial Intelligence},
         year = "2019",
        month = "Jun",
          eid = {arXiv:1906.07754},
        pages = {arXiv:1906.07754},
archivePrefix = {arXiv},
       eprint = {1906.07754},
 primaryClass = {cs.DS},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190607754O},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{2019arXiv190603161A,
       author = {{Aglietti}, Virginia and {Bonilla}, Edwin V. and {Damoulas}, Theodoros and
         {Cripps}, Sally},
        title = "{Structured Variational Inference in Continuous Cox Process Models}",
    booktitle = {Advances in Neural Information Processing Systems 32 ({NeurIPS'19})},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Statistics - Applications},
         year = "2019",
        month = "Jun",
archivePrefix = {arXiv},
       eprint = {1906.03161},
 primaryClass = {stat.ML},
          url = {https://ui.adsabs.harvard.edu/abs/2019arXiv190603161A}
}

@ARTICLE{2019arXiv190402063K,
       author = {{Knoblauch}, Jeremias and {Jewson}, Jack and {Damoulas}, Theodoros},
        title = "{Generalized Variational Inference}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = "2019",
          eid = {arXiv:1904.02063},
        pages = {arXiv:1904.02063},
archivePrefix = {arXiv},
       eprint = {1904.02063},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190402063K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{amj26:GJL17,
  author = {P. Guarniero and A. M. Johansen and A. Lee},
  title = {The Iterated Auxiliary Particle Filter},
  journal = {Journal of the American Statistical Association},
  optkey = {},
  year = {2017},
  volume = {112},
  number = {520},
  pages = {1636--1647}
}

@article{amj26:LJNK+17,
  author = {F. Lindsten and A. M. Johansen and C. A. Naesseth and B. Kirkpatrick and T. Sch{\"o}n and J. A. D. Aston and A.
Bouchard-C{\^o}t{\'e}},
  title = {Divide and Conquer with Sequential {M}onte {C}arlo Samplers},
  journal = {Journal of Computational and Graphical Statistics},
  year = {2017},
  optkey = {},
  volume = {26},
  number = {2},
  pages = {445--458},
  optmonth = {},
  optnote = {},
  optannote = {}
}

@techreport{amj26:FDJ18,
  author = {A. Finke and A. Doucet and A. M. Johansen},
  title = {Limit Theorems for Sequential {MCMC} Methods},
  journal = {ArXiv},
  institution = arxiv,
  year = 2018,
  optkey = {},
  type = {ArXiv mathematics e-print},
  number = {1807.01057},
  optaddress = {},
  month = jul,
  optnote = {},
  optannote = {}
}

@techreport{amj26:RJLW18,
  author = {L. J. Rendell and A. M. Johansen and A. Lee and N. Whiteley},
  title = {Global Consensus {M}onte {C}arlo},
  institution = arxiv,
  journal = {ArXiv},
  year = 2018,
  optkey = {},
  type = {ArXiv mathematics e-print},
  number = {1807.09288},
  optaddress = {},
  month = jul,
  optnote = {},
  optannote = {}
}

@article{Wang2018,
author = {Wang, Kangrui and Chakrabarty, Dalia},
year = {2018},
month = {03},
url={https://arxiv.org/abs/1803.04582},
pages = {},
journal = {{arXiv}},
title = {Deep Bayesian Supervised Learning given Hypercuboidally-shaped, Discontinuous Data, using Compound Tensor-Variate & Scalar-Variate Gaussian Processes}
}

@ARTICLE{2019arXiv190312044D,
       author = {{Deniz Akyildiz}, {\"O}mer and {M{\'\i}guez}, Joaqu{\'\i}n},
        title = "{Convergence rates for optimised adaptive importance samplers}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Computation, Statistics - Methodology, Statistics - Machine Learning},
         year = "2019",
        month = "Mar",
          eid = {arXiv:1903.12044},
        pages = {arXiv:1903.12044},
archivePrefix = {arXiv},
       eprint = {1903.12044},
 primaryClass = {stat.CO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190312044D},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{CormodeDickensWoodruff18,
  author = {Graham Cormode and Charlie Dickens and David P. Woodruff},
  title = {Leveraging Well-Conditioned Bases: Streaming and Distributed Summaries in Minkowski $p$-Norms},
  booktitle = {International Conference on Machine Learning, ({ICML'18})},
  year = 2018,
  url = {../papers/wcb.pdf},
  poster = {../slides/leveragingwcb-poster.pdf},
  abstract = {
    Work on approximate linear algebra
    has led to efficient distributed and streaming
    algorithms for
    problems such as approximate matrix multiplication, low rank approximation,
    and regression, primarily for the Euclidean norm $l_2$.
    We study other
    $l_p$ norms, which are more robust for $p < 2$, and can be used
    to find outliers for $p > 2$.
    Unlike previous algorithms for such norms,
  we give algorithms that are (1) deterministic, (2) work simultaneously
  for every $p \geq 1$, including $p$ infinite, and (3) can be
    implemented in both
    distributed and streaming environments. We apply our results to $l_p$-regression,
    entrywise $l_1$-low rank approximation,
    and approximate matrix multiplication.
}
}

@inproceedings{CormodeKulkarniSrivastava18SIGMOD,
  author = {Graham Cormode and Tejas Kulkarni and Divesh Srivastava},
  title = {Marginal Release Under Local Differential Privacy},
  booktitle = {{ACM} {SIGMOD} International 
                    Conference on Management of Data ({SIGMOD'18})},
  url = {../papers/sigmod18.pdf},
  slides = {../slides/marginals-sigmod.pdf},
  poster = {../slides/marginals-sigmod-poster.pdf},
  year = 2018,
  abstract = {Many analysis and machine learning tasks require the availability of
marginal statistics on multidimensional datasets while providing
strong privacy guarantees for the data subjects.
Applications for these statistics range from finding correlations
in the data to fitting sophisticated prediction models.
In this paper, we provide a set of algorithms for materializing marginal
statistics under the strong model of local differential privacy.
We prove the first tight theoretical bounds on the accuracy of marginals
compiled under each approach, perform empirical evaluation to
confirm these bounds, and evaluate them for tasks such as modeling and
correlation testing.
Our results show that releasing information based on (local) Fourier
transformations of the input is preferable to alternatives based
directly on (local) marginals.}
}

@inproceedings{CormodeHickey18b,
  author = {Graham Cormode and Christopher Hickey},
  title = {You Can Check Others' Work More Quickly Than Doing It Yourself},
  booktitle = {International Conference on Data Engineering ({ICDE'18})},
  year = 2018,
  url = {../papers/lightning.pdf},
  slides = {../slides/sip2018icde.pdf},
  abstract = {Much of computer science involves problems where
it is considered to be easier to check that an answer is correct than
to find a correct answer (the complexity class NP). In this talk,
we outline results that apply this notion to checking outsourced
computations for data analytics.}
}
@inproceedings{ZhangTirthapuraCormode18,
  author = {Yu Zhang and Srikanta Tirthapura and Graham Cormode},
  title = {Learning Graphical Models from a Distributed Stream},
  booktitle = {International Conference on Data Engineering ({ICDE'18})},
  year = 2018,
  url = {../papers/distributedBayes.pdf},
  poster = {../slides/distbayesposter.pdf},
  abstract = {
 A current challenge for data management systems is to support the
 construction and maintenance of machine learning models over data that
 is large, multi-dimensional, and evolving.
 While systems that could support these tasks are emerging, the need to scale
 to distributed, streaming data requires new models and algorithms.
 In this setting, as well as computational scalability and model
 accuracy, we also need to minimize the amount of communication between
 distributed processors, which is the chief component of latency.
 
 We study Bayesian networks, the workhorse of graphical models, 
 and present a communication-efficient method for continuously learning 
 and maintaining a Bayesian network model over data that is 
 arriving as a distributed stream partitioned across multiple processors. 
 We show a strategy for maintaining model parameters 
 that leads to an exponential reduction in communication when 
 compared with baseline approaches to maintain the exact MLE (maximum
 likelihood estimation).
 Meanwhile, our strategy provides similar prediction errors for the
 target distribution and for classification tasks.}
}
@inproceedings{CormodeHickey18,
  author = {Graham Cormode and Chris Hickey},
  title = {Cheap Checking for Cloud Computing: 
            Statistical Analysis via Annotated Data Streams},
  booktitle = {The 21st international conference on artificial intelligence and statistics ({AISTATS}'18)},
  year = 2018,
  poster = {../slides/cheapcheckingposter.pdf},
  url = {../papers/cheapchecking.pdf},
  abstract = {As the popularity of outsourced computation increases, questions of 
accuracy and trust between the client and the cloud computing services
become ever more relevant.
Our work aims to provide fast and practical methods to verify analysis
of large data sets, where the client's computation and memory and
costs are kept to a minimum.
Our verification protocols are based on defining ``proofs'' which are easy
to create and check.
These add only a small overhead to reporting the result of the
computation itself. 
We build up a series of protocols for elementary statistical methods, to create more complex protocols for Ordinary Least Squares, Principal Component Analysis and Linear Discriminant Analysis. 
We show that these are very efficient in practice. }
}
 @inproceedings{CormodeKulkarniSrivastava18,
  author = {Graham Cormode and Tejas Kulkarni and Divesh Srivastava},
  title = {Constrained Private Mechanisms for Count Data},
  booktitle = {International Conference on Data Engineering ({ICDE'18})},
  year = 2018,
  url = {../papers/constrainedmechanisms.pdf},
  slides = {../slides/icde18constrained.pdf},
  abstract = {
    Concern about how to aggregate sensitive user data without compromising
    individual privacy is a major barrier to greater availability of
    data.
    The model of differential privacy has emerged as an accepted model to
    release sensitive information while giving a statistical guarantee for
    privacy.
    Many different algorithms are possible to address different target
    functions.
    We focus on the core problem of count queries, and seek to design
    {\em mechanisms} to release data associated with a group of $n$
    individuals.  
     
    Prior work has focused on designing mechanisms by raw optimization of a
    loss function, without regard to the consequences on the results. 
    This can leads to mechanisms with undesirable properties, such as
    never reporting some outputs (gaps), and overreporting others
    (spikes). 
    We tame these pathological behaviors by introducing a set of desirable properties that
    mechanisms can obey.
    Any combination of these can be satisfied by solving a linear program (LP)
    which minimizes a cost function, with constraints enforcing the properties.
    We focus on a particular cost function, and 
    provide explicit constructions that are optimal for certain
    combinations of properties, and show a closed form for their cost.
    In the end, there are only a handful of distinct optimal mechanisms to choose
    between: one is the well-known (truncated) geometric mechanism; the
    second a novel mechanism that we introduce here, and the remainder are
    found as the solution to particular LPs.
    These all avoid the bad behaviors we identify. 
    We demonstrate in a set of experiments on real and
    synthetic data which is preferable in practice, for different
combinations of data distributions, constraints, and privacy parameters. }
}


@inproceedings{JorgensenYuCormode16,
  author = {Zach Jorgensen and
               Ting Yu and
               Graham Cormode},
  title = {Publishing Attributed Social Graphs with Formal Privacy Guarantees},
  booktitle = {{ACM} {SIGMOD} International 
                    Conference on Management of Data ({SIGMOD'16})},
  pages = {107--122},
  year = {2016},
  url = {../papers/attributedgraph.pdf},
  slides = {../slides/graphanon-sigmod.pdf},
  poster = {../slides/graphanon16-poster.pdf},
  link = {http://dl.acm.org/citation.cfm?doid=2882903.2915215},
  abstract = {Many data analysis tasks rely on the abstraction of a graph to represent
relations between entities, with attributes on the nodes and edges.  
Since the relationships encoded are often sensitive, we seek effective
ways to release representative graphs which nevertheless protect the
privacy of the data subjects.
Prior work on this topic has focused primarily on the graph
structure in isolation, and has not provided ways to handle richer
graphs with correlated attributes.

We introduce an approach to release such graphs under the strong guarantee
of differential privacy.
We adapt existing graph models, and introduce a new one, and show how
to augment them with meaningful privacy.
This provides a complete workflow, where the input is a sensitive
graph, and the output is a realistic synthetic graph.
Our experimental study demonstrates that our process produces useful,
accurate attributed graphs. }
}
@article{CormodeJowhari18,
  title = {$L_p$ Samplers and Their Applications: A Survey},
  author = {Graham Cormode and Hossein Jowhari},
  journal = {ACM Computing Surveys},
  url = {../papers/Lpsurvey.pdf},
  year = 2018,
  abstract = {The notion of $L_p$ sampling, and corresponding algorithms known as $L_p$ samplers, have found a wide range of applications in the design of
data stream algorithms and beyond.
In this survey we present some of the core algorithms to achieve
  this sampling distribution based on ideas from hashing, sampling and
  sketching. 
We give results for the special cases of insertion-only
inputs, lower bounds for the sampling problems, and ways to
efficiently sample multiple elements.
We describe a range of applications of 
$L_p$ drawing on problems across the domain of computer science,
from matrix and graph computations, as well as to geometric and vector
streaming problems.}
}

@article{Cormode17,
  author = {Graham Cormode},
  title = {Data Sketching},
  journal = {Communications of the {ACM} ({CACM'18})},
  volume = 60,
  number = 9,
  pages = {48--55},
  year = 2017,
  url = {../papers/cacm-sketch.pdf},
  pubsite = {http://dl.acm.org/citation.cfm?doid=3080008},
  abstract = {Do you ever feel overwhelmed by a constant stream of information?  It
can seem like there is a barrage of new email and text messages
arriving, phone calls, articles to read, and knocks on the door.
Putting these pieces together to keep track of what's important can be a real challenge. 

The same information overload is of concern in many computational settings. 
For example, telecommunications companies want to keep track of the activity on their network, to identify the overall network health, and spot anomalies or changes in behavior.  Yet, the scale of events occurring is huge: many millions of network events per hour, per network element. 
And while new technologies allow the scale and granularity of events being monitored to increase by orders of magnitude, the capacity of computing elements to make sense of these (processors, memory and disks) is barely increasing.  
Even on a small scale, the amount of information may be too large to
store in an impoverished setting (say, an embedded device),
or be too big to conveniently keep in fast storage. 


In response to this challenge, the model of streaming data processing has grown in popularity. 
In this setting, the aim is no longer to capture, store and index
every minute event, but rather to quickly process each observation to
create some summary of the current state.
Following its processing, an event is dropped, and is no longer accessible. 
The summary that is retained is often referred to as sketch of the
data. 
Coping with the vast scale of information means making a number of compromises: the description of the world is approximate, rather than exact; 
the nature of queries to be answered must be decided in advance, rather than after the fact; and some questions are now insoluble. 
However, the ability to process vast quantities of data at blinding speeds with modest resources can more than make up for these limitations. 
As a consequence, streaming methods have been adopted in a number of domains, starting with telecommunications, but spreading to search engines, social networks, finance, and time-series analysis.  
These ideas are also finding application in areas where traditional approaches are applicable, but the rough and ready sketching approach is more cost-effective.
Successful applications of sketching involve a mixture of algorithmic tricks, systems know-how, and mathematical insight, and have led to new research contributions in each of these areas. 

In this article, we introduce the ideas behind, and applications, of sketching, with a focus on the algorithmic innovations. 
That is, we describe some algorithmic developments in the abstract,
and then indicate the subsequent steps needed to put them into
practice, with examples. 
We will see four novel algorithmic ideas, and discuss some emerging areas.}
}

@inproceedings{Aits2019,
author = {Dominic Aits and Alexander Carver and Paolo Turrini},
title = {Group Segregation in Social Networks},
year = {2019},
booktitle = {Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems ({AAMAS}'19)}
}

@inproceedings{Grandi2019,
author = {Umberto Grandi and Davide Grossi and Paolo Turrini},
title = {Negotiable Votes: Pre-Vote Negotiations in Binary Voting with Non-Manipulable Rules},
year = {2019},
booktitle = {Journal of Artificial Intelligence Research ({JAIR}'19)}
}

@inproceedings{Wang2019,
title = {EV-Gait: Event-based Robust Gait Recognition using Dynamic Vision Sensors},
author = {Yanxiang Wang and Bowen Du and Yiran Shen and Kai Wu and Guangrong Zhao and Jianguo Sun and Hongkai Wen},
booktitle = {IEEE International Conference on Computer Vision and Pattern Recognition ({CVPR}'19)},
year = {2019}
}

@inproceedings{Yang2018,
title = {Dense 3D Object Reconstruction from a Single Depth View},
author = {Bo Yang and Stefano Rosa and Andrew Markham and Niki Trigoni and Hongkai Wen},
booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence ({TPAMI}'18)},
year = {2018}
}

@inproceedings{Clark2017a,
title = {VidLoc: A Deep Spatio-Temporal Model for 6-DoF Video-Clip Relocalization},
author = {Ronald Clark and Sen Wang and Hongkai Wen and Andrew Markham and Niki Trigoni},
booktitle = {IEEE Conference on Computer Vision and Pattern Recognition ({CVPR}'17)},
year = {2017},
}

@inproceedings{Clark2017b,
title = {VINet: Visual-Inertial Odometry as a Sequence-to-sequence Learning},
author = {Ronald Clark and Sen Wang and Hongkai Wen and Andrew Markham and Niki Trigoni},
booktitle = {The 31st AAAI Conference on Artificial Intelligence ({AAAI}'17)}, 
year = {2017}
}

@inproceedings{Aglietti2019,
author = {Aglietti, V and Damoulas, T and Bonilla, E},
title = {Efficient Inference in Multi-task Cox Process Models},
month = {1},
year = {2019},
url = {https://arxiv.org/abs/1805.09781},
booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics {(AISTATS'19)}},
abstract = {We generalize the log Gaussian Cox process (LGCP) framework to model multiple correlated point data jointly. The observations are treated as realizations of multiple LGCPs, whose log intensities are given by linear combinations of latent functions drawn from Gaussian process priors. The combination coefficients are also drawn from Gaussian processes and can incorporate additional dependencies. We derive closed-form expressions for the moments of the intensity functions and develop an efficient variational inference algorithm that is orders of magnitude faster than competing deterministic and stochastic approximations of multivariate LGCP, coregionalization models, and multi-task permanental processes. Our approach outperforms these benchmarks in multiple problems, offering the current state of the art in modeling multivariate point processes.}
}

@article{DBLP:journals/corr/abs-1902-09335,
  author    = {Sabrina Evans and
               Paolo Turrini},
  title     = {Similarity Measures based on Local Game Trees},
  journal   = {CoRR},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.09335},
  archivePrefix = {arXiv},
  eprint    = {1902.09335},
  timestamp = {Mon, 04 Mar 2019 15:54:34 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1902-09335},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-1902-07083,
  author    = {Charlotte Roman and
               Paolo Turrini},
  title     = {How does information affect asymmetric congestion games?},
  journal   = {CoRR},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.07083},
  archivePrefix = {arXiv},
  eprint    = {1902.07083},
  timestamp = {Mon, 04 Mar 2019 15:54:37 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1902-07083},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/atal/CarverT18,
  author    = {Alex Carver and
               Paolo Turrini},
  title     = {Intolerance does not Necessarily Lead to Segregation: {A} Computer-aided
               Analysis of the Schelling Segregation Model},
  booktitle = {Proceedings of the 17th International Conference on Autonomous Agents
               and MultiAgent Systems, ({AAMAS}'18)},
  pages     = {1889--1890},
  year      = {2018},
  crossref  = {DBLP:conf/atal/2018},
  url       = {http://dl.acm.org/citation.cfm?id=3238013},
  timestamp = {Mon, 16 Jul 2018 09:21:17 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/atal/CarverT18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Knoblauch2018NIPS,
author = {Knoblauch, Jeremias and Jewson, Jack and Damoulas, Theo},
year = {2018},
month = {06},
title = {Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences},
booktitle={Advances in Neural Information Processing Systems ({NeurIPS}'18)},
url={https://arxiv.org/abs/1806.02261},
abstract = {We present the very first robust Bayesian Online Changepoint Detection algorithm through General Bayesian Inference (GBI) with $\beta$-divergences. The resulting inference procedure is doubly robust for both the predictive and the changepoint (CP) posterior, with linear time and constant space complexity. We provide a construction for exponential models and demonstrate it on the Bayesian Linear Regression model. In so doing, we make two additional contributions: Firstly, we make GBI scalable using Structural Variational approximations that are exact as $\beta \to 0$. Secondly, we give a principled way of choosing the divergence parameter $\beta$ by minimizing expected predictive loss on-line. We offer the state of the art and improve the False Discovery Rate of CPs by more than 80% on real world data.}
}
@inproceedings{Knoblauch2018ICML,
  title={Spatio-temporal Bayesian On-line Changepoint Detection with Model Selection},
  author={Jeremias Knoblauch and Theodoros Damoulas},
  booktitle={International Conference on Machine Learning ({ICML}'18)},
  year={2018},
  url={https://arxiv.org/abs/1805.05383},
  abstract = {Bayesian On-line Changepoint Detection is extended to on-line model selection and non-stationary spatio-temporal processes. We propose spatially structured Vector Autoregressions (VARs) for modelling the process between changepoints (CPs) and give an upper bound on the approximation error of such models. The resulting algorithm performs prediction, model selection and CP detection on-line. Its time complexity is linear and its space complexity constant, and thus it is two orders of magnitudes faster than its closest competitor. In addition, it outperforms the state of the art for multivariate data.}
}

@inproceedings{DBLP:conf/aaai/GrandiST18,
  author    = {Umberto Grandi and
               James Stewart and
               Paolo Turrini},
  title     = {The Complexity of Bribery in Network-Based Rating Systems},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence
               {(AAAI'18)}, the 30th innovative Applications of Artificial Intelligence
               {(IAAI'18)}, and the 8th {AAAI} Symposium on Educational Advances in
               Artificial Intelligence {(EAAI'18)}},
  pages     = {1047--1054},
  year      = {2018},
  crossref  = {DBLP:conf/aaai/2018},
  url       = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17201},
  timestamp = {Tue, 23 Oct 2018 06:42:15 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/aaai/GrandiST18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Tsakalidis2018,
  author    = {Adam Tsakalidis and
               Maria Liakata and
               Theodoros Damoulas and
               Alexandra I. Cristea},
  title     = {Can We Assess Mental Health through Social Media and Smart Devices?
               Addressing Bias in Methodology and Evaluation},
  journal   = {European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases ({ECML-PKDD}'18)},
  year      = {2018},
  url       = {http://arxiv.org/abs/1807.07351},
  archivePrefix = {arXiv},
  eprint    = {1807.07351},
  timestamp = {Wed, 09 Jan 2019 16:35:11 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1807-07351},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/ijcai/HarrensteinTW17,
  author    = {Paul Harrenstein and
               Paolo Turrini and
               Michael Wooldridge},
  title     = {Characterising the Manipulability of Boolean Games},
  booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence ({IJCAI}'17)},
  pages     = {1081--1087},
  year      = {2017},
  crossref  = {DBLP:conf/ijcai/2017},
  url       = {https://doi.org/10.24963/ijcai.2017/150},
  doi       = {10.24963/ijcai.2017/150},
  timestamp = {Wed, 27 Jun 2018 12:24:11 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/ijcai/HarrensteinTW17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inbook{Meagher2017,
author = {Meagher, Joe  and  Damoulas, Theo and Jones, K. E and Girolami, Mark},
year={2017},
title = {Phylogenetic Gaussian Processes for Bat Echolocation},
booktitle = {Statistical Data Science ({SDS}'17)},
chapter = {Chapter 7},
pages = {111-124},
doi = {10.1142/9781786345400_0007},
URL = {https://www.worldscientific.com/doi/abs/10.1142/9781786345400_0007},
eprint = {https://www.worldscientific.com/doi/pdf/10.1142/9781786345400_0007},
    abstract = {The reconstruction of ancestral echolocation calls is an important part of understanding the evolutionary history of bats. General techniques for the ancestral reconstruction of function-valued traits have recently been proposed. A full implementation of phylogenetic Gaussian processes for the ancestral reconstruction of function-valued traits representing bat echolocation calls is presented here. A phylogenetic signal was found in the data and ancestral reconstruction performed. This promising preliminary analysis paves the way for more realistic models for the evolution of echolocation in bats. }
}

@article{kuntz2022product,
  title={Product-form estimators: exploiting independence to scale up Monte Carlo},
  author={Kuntz, Juan and Crucinio, Francesca R and Johansen, Adam M},
  journal={Statistics and Computing},
  volume={32},
  number={1},
  pages={1--22},
  year={2022},
  publisher={Springer}
}

@article{cormode2021frequency,
  title={Frequency estimation under local differential privacy},
  author={Cormode, Graham and Maddock, Samuel and Maple, Carsten},
  journal={Proceedings of the VLDB Endowment},
  volume={14},
  number={11},
  pages={2046--2058},
  year={2021},
  publisher={VLDB Endowment}
}

@article{thesingarajah2021node,
  title={The Node-wise Pseudo-marginal Method},
  author={Thesingarajah, Denishrouf and Johansen, Adam M},
  journal={arXiv preprint arXiv:2109.08573},
  year={2021}
}

@inproceedings{shekelyan2021sequential,
  title={Sequential Random Sampling Revisited: Hidden Shuffle Method},
  author={Shekelyan, Michael and Cormode, Graham},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3628--3636},
  year={2021},
  organization={PMLR}
}
